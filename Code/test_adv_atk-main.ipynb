{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca56b96",
   "metadata": {},
   "source": [
    "### Variable Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4698d01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # of images is: 50000 on val mode!\n",
      "Start validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Val Accuracy: 0.65297/Robustness: 0.56490:  60%|███████████████████████████████████████████████████████████████████████████████████████▌                                                         | 1259/2084 [14:37<09:34,  1.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13692/2756572184.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#         break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0matk_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_13692/2756572184.py\u001b[0m in \u001b[0;36matk_func\u001b[0;34m(atk)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mnorm_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m4096.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0madv_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4096\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchattacks/attack.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_normalization_applied\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0madv_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0madv_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchattacks/attacks/pgd.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Update adversarial images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             grad = torch.autograd.grad(cost, adv_images,\n\u001b[0;32m---> 71\u001b[0;31m                                        retain_graph=False, create_graph=False)[0]\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0madv_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madv_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    223\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    224\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os, glob\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from dataset import *\n",
    "from model import *\n",
    "from torch.nn.parallel import DataParallel\n",
    "import tqdm\n",
    "import torchattacks\n",
    "from tqdm import trange\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.models as tm\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "from skimage.feature import local_binary_pattern\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "##=============Config===================\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device='cuda'\n",
    "\n",
    "\n",
    "### original inference process ###\n",
    "stmodel= tm.resnet50().to(device)\n",
    "stmodel = DataParallel(stmodel)\n",
    "stmodel.load_state_dict(torch.load('checkpoint2/final_hog.pt'))\n",
    "val_ltp = A.Compose([A.Lambda(name='ltp', image=ltp_transform_train, p=1, always_apply=True)])\n",
    "\n",
    "\n",
    "val_dataset = featDataset(0, \"val.txt\", root='/hdd3/ILSVRC/Data/imagenet/', mode='val', feat='ltp')\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=24, drop_last=False, \n",
    "                                         num_workers=16, sampler=None, shuffle=True)\n",
    "    \n",
    "def atk_func(atk):\n",
    "#     atk = torchattacks.FGSM(stmodel, eps=16/255)\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    stmodel.eval()\n",
    "    print('Start validating')\n",
    "    t = trange(len(val_loader), desc='Average Val Accuracy', leave=True)\n",
    "    val_acc, val_acc2 = [], []\n",
    "    for step_val, (feat,X,y) in zip(t, val_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        c=feat.to(device)\n",
    "        ##======================\n",
    "\n",
    "#         adv_images1 = atk(X/255.0, y)\n",
    "#         adv_images = adv_images1.permute(0,2,3,1).cpu().numpy().astype(np.float)*255\n",
    "\n",
    "#         for b in range(adv_images.shape[0]):\n",
    "#             adv_images[b] = val_ltp(image=adv_images[b])['image']\n",
    "#     #         for c in range(3):\n",
    "#     #             adv_images[b,:,:,c] =local_binary_pattern(adv_images[b,:,:,c], n_points, radius, 'ror')\n",
    "\n",
    "#     #     adv_images[np.isnan(adv_images)] = 0\n",
    "#     #     adv_images = (adv_images / float(2**8) -0.5) * 2\n",
    "#         adv_images = (adv_images*0.125 -0.5) * 2\n",
    "\n",
    "#         adv_images = torch.Tensor(adv_images).permute(0,3,1,2).cuda()\n",
    "        \n",
    "        norm_feat = (feat +1) / 4096.0\n",
    "        adv_images = atk(norm_feat, y) * 4096 -1\n",
    "        \n",
    "        \n",
    "        outputs = stmodel(adv_images)\n",
    "        outputs2 = stmodel(feat)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        val_acc2.append( (pred == y).sum().item()/y.size(0) )\n",
    "        _, pred2 = torch.max(outputs2.data, 1)\n",
    "        val_acc.append( (pred2 == y).sum().item()/y.size(0) )\n",
    "\n",
    "    #     plt.imshow(adv_images[0].permute(1,2,0).cpu().data)\n",
    "    #     plt.show()\n",
    "        t.set_description(\"Average Val Accuracy: %.5f/Robustness: %.5f\" % (np.mean(np.array(val_acc)), np.mean(np.array(val_acc2))))\n",
    "        t.refresh() # to show immediately the update\n",
    "#         im1 = adv_images[0].permute(1,2,0).cpu().numpy() \n",
    "#         plt.imshow(im1)\n",
    "#         plt.show()\n",
    "#         im2 = norm_feat[0].permute(1,2,0).cpu().numpy()\n",
    "#         plt.imshow(im2)\n",
    "#         plt.show()\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "#         break\n",
    "\n",
    "atk_func(torchattacks.PGD(stmodel, eps=8/255, steps=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4aa927",
   "metadata": {},
   "source": [
    "### BPDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe4143b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # of images is: 50000 on val mode!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▏                                                                                                                                                                                                   | 1/90 [01:53<2:47:47, 113.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5944359302520752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|████▍                                                                                                                                                                                                 | 2/90 [03:43<2:43:18, 111.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.633886456489563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██████▌                                                                                                                                                                                               | 3/90 [05:32<2:40:06, 110.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6110250353813171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|████████▊                                                                                                                                                                                             | 4/90 [07:21<2:37:28, 109.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6607457995414734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███████████                                                                                                                                                                                           | 5/90 [09:11<2:35:46, 109.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6905728578567505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████████████▏                                                                                                                                                                                        | 6/90 [11:03<2:34:37, 110.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6236686110496521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███████████████▍                                                                                                                                                                                      | 7/90 [12:52<2:32:21, 110.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6522784233093262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|█████████████████▌                                                                                                                                                                                    | 8/90 [14:42<2:30:21, 110.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6678498983383179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████████████████▊                                                                                                                                                                                  | 9/90 [16:31<2:28:11, 109.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5522041320800781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████████████████▉                                                                                                                                                                               | 10/90 [18:22<2:26:44, 110.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6825758814811707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████████████████████████                                                                                                                                                                             | 11/90 [20:13<2:25:14, 110.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6413159370422363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████████████████████▎                                                                                                                                                                          | 12/90 [22:03<2:23:29, 110.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6657491326332092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████████████████████████▍                                                                                                                                                                        | 13/90 [23:54<2:21:42, 110.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6708210110664368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████████████████████████████▋                                                                                                                                                                      | 14/90 [25:43<2:19:23, 110.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6297670602798462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████████████████████████▊                                                                                                                                                                    | 15/90 [27:33<2:17:30, 110.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6846252679824829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████████████████████████████████                                                                                                                                                                  | 16/90 [29:21<2:15:05, 109.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6185950636863708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█████████████████████████████████████▏                                                                                                                                                               | 17/90 [31:10<2:13:08, 109.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6398006081581116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████████████████████████████▍                                                                                                                                                             | 18/90 [32:59<2:11:09, 109.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6784878373146057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████████████████████████████▌                                                                                                                                                           | 19/90 [34:48<2:09:01, 109.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5731459856033325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|███████████████████████████████████████████▊                                                                                                                                                         | 20/90 [36:36<2:06:58, 108.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6333252787590027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████████████████████████████████▉                                                                                                                                                       | 21/90 [38:26<2:05:23, 109.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.681962251663208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|████████████████████████████████████████████████▏                                                                                                                                                    | 22/90 [40:15<2:03:43, 109.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622971773147583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██████████████████████████████████████████████████▎                                                                                                                                                  | 23/90 [42:04<2:01:50, 109.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7462064623832703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|████████████████████████████████████████████████████▌                                                                                                                                                | 24/90 [43:53<1:59:54, 109.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.605003297328949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████████████████████████████████████▋                                                                                                                                              | 25/90 [45:44<1:58:40, 109.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6506227254867554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████████████████████████████████████████████████▉                                                                                                                                            | 26/90 [47:32<1:56:21, 109.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6656076908111572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████████████████████████████████████████                                                                                                                                          | 27/90 [49:19<1:54:05, 108.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6976550817489624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████████████████████████████████████████▎                                                                                                                                       | 28/90 [51:07<1:52:00, 108.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6282108426094055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███████████████████████████████████████████████████████████████▍                                                                                                                                     | 29/90 [52:55<1:50:06, 108.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6637194156646729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|█████████████████████████████████████████████████████████████████▋                                                                                                                                   | 30/90 [54:43<1:48:11, 108.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6250649690628052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████████████████████████████████████████████▊                                                                                                                                 | 31/90 [56:35<1:47:19, 109.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7232972383499146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|██████████████████████████████████████████████████████████████████████                                                                                                                               | 32/90 [58:25<1:45:53, 109.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6234517097473145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███████████████████████████████████████████████████████████████████████▌                                                                                                                           | 33/90 [1:00:16<1:44:28, 109.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6831804513931274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                         | 34/90 [1:02:05<1:42:21, 109.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6071536540985107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████████████████████████████████████████████████▊                                                                                                                       | 35/90 [1:03:56<1:40:51, 110.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5442200303077698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████████████████████████████████████████████████████                                                                                                                     | 36/90 [1:05:46<1:39:05, 110.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6727399826049805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 37/90 [1:07:35<1:36:52, 109.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5644145011901855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████████████████████████████████████████████████████▎                                                                                                                | 38/90 [1:09:26<1:35:27, 110.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6117665767669678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                                              | 39/90 [1:11:17<1:33:52, 110.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6139953136444092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                                            | 40/90 [1:13:09<1:32:27, 110.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5465528964996338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                          | 41/90 [1:15:00<1:30:34, 110.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6164834499359131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                        | 42/90 [1:16:51<1:28:44, 110.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5880075693130493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                     | 43/90 [1:18:42<1:26:58, 111.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.647610068321228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                   | 44/90 [1:20:33<1:24:58, 110.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6620799899101257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                 | 45/90 [1:22:25<1:23:25, 111.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5562500357627869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|███████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                               | 46/90 [1:24:17<1:21:40, 111.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6450087428092957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                             | 47/90 [1:26:09<1:20:02, 111.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7351558804512024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                           | 48/90 [1:28:00<1:18:01, 111.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6249393224716187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                        | 49/90 [1:29:51<1:16:01, 111.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6421890258789062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                      | 50/90 [1:31:41<1:13:59, 110.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6739494800567627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 51/90 [1:33:32<1:12:11, 111.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7303183078765869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 52/90 [1:35:23<1:10:21, 111.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5973657965660095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                | 53/90 [1:37:14<1:08:25, 110.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5962247252464294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 54/90 [1:39:05<1:06:33, 110.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635012149810791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 55/90 [1:40:55<1:04:33, 110.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6839419603347778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 56/90 [1:42:45<1:02:32, 110.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6156566143035889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                       | 57/90 [1:44:36<1:00:47, 110.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7451116442680359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 58/90 [1:46:27<59:00, 110.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6023986339569092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                   | 59/90 [1:48:17<57:08, 110.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6671872138977051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                 | 60/90 [1:50:10<55:35, 111.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6358116269111633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 61/90 [1:51:59<53:32, 110.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6260062456130981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 62/90 [1:53:51<51:46, 110.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6345858573913574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                           | 63/90 [1:55:41<49:47, 110.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6657776236534119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 64/90 [1:57:33<48:06, 111.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648952066898346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 65/90 [1:59:25<46:22, 111.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.621436357498169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                    | 66/90 [2:01:16<44:28, 111.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6390544772148132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 67/90 [2:03:06<42:29, 110.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6192572712898254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 68/90 [2:04:57<40:40, 110.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6271030902862549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                              | 69/90 [2:06:48<38:54, 111.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6504808068275452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                           | 70/90 [2:08:39<36:58, 110.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6056793928146362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 71/90 [2:10:29<35:05, 110.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.667262077331543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 72/90 [2:12:19<33:10, 110.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6502650380134583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 73/90 [2:14:10<31:22, 110.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6633138060569763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 74/90 [2:16:02<29:36, 111.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686622679233551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                | 75/90 [2:17:53<27:45, 111.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5439849495887756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                              | 76/90 [2:19:45<25:55, 111.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6612194776535034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 77/90 [2:21:35<24:03, 111.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6849087476730347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 78/90 [2:23:26<22:12, 111.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6333601474761963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                        | 79/90 [2:25:16<20:14, 110.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6133249402046204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 80/90 [2:27:07<18:26, 110.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6499537825584412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 81/90 [2:28:57<16:34, 110.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7067448496818542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 82/90 [2:30:48<14:44, 110.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6883947253227234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 83/90 [2:32:38<12:54, 110.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608311653137207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 84/90 [2:34:29<11:03, 110.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5504240393638611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 85/90 [2:36:20<09:13, 110.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6187568306922913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 86/90 [2:38:11<07:23, 110.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6198277473449707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 87/90 [2:40:04<05:34, 111.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6335012316703796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 88/90 [2:41:53<03:41, 110.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5628294944763184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 89/90 [2:43:43<01:50, 110.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6765177845954895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [2:45:34<00:00, 110.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6423500776290894\n",
      "Start validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Val Accuracy: 0.58911/Robustness: 0.47175: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2084/2084 [26:01<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os, glob\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from dataset import *\n",
    "from model import *\n",
    "from torch.nn.parallel import DataParallel\n",
    "import tqdm\n",
    "import torchattacks\n",
    "from tqdm import trange\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.models as tm\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "from skimage.feature import local_binary_pattern\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torch.nn.functional as F\n",
    "##=============Config===================\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device='cuda'\n",
    "\n",
    "class BPDA(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BPDA, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 3, 3, stride=1, padding=1)\n",
    "        # an affine operation: y = Wx + b\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "### original inference process ###\n",
    "\n",
    "val_ltp = A.Compose([A.Lambda(name='ltp', image=ltp_transform_train, p=1, always_apply=True)])\n",
    "\n",
    "\n",
    "val_dataset = featDataset(0, \"val.txt\", root='/hdd3/ILSVRC/Data/imagenet/', mode='val', feat='ltp')\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=24, drop_last=False, \n",
    "                                         num_workers=16, sampler=None, shuffle=True)\n",
    "    \n",
    "def atk_func():\n",
    "#     t = trange(len(val_loader), desc='Average Val Accuracy', leave=True) \n",
    "    bpda = BPDA().to(device)\n",
    "    mse = torch.nn.MSELoss()\n",
    "    opt = torch.optim.Adam(bpda.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=30, gamma=0.1)\n",
    "    for ep in tqdm.tqdm(range(90)):\n",
    "#         t = trange(len(val_loader), desc='Average Val Accuracy', leave=True) \n",
    "        for step_val, (feat,X,y) in enumerate(val_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            c=feat.to(device)\n",
    "#             import pdb\n",
    "#             pdb.set_trace()\n",
    "            opt.zero_grad()\n",
    "            pred = bpda(X)\n",
    "            loss = mse(pred, c)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "        print(loss.item())\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    print('Start validating')\n",
    "   \n",
    "    val_acc, val_acc2 = [], []\n",
    "    \n",
    "    stmodel= tm.resnet50().to(device)\n",
    "    stmodel = DataParallel(stmodel)\n",
    "    stmodel.load_state_dict(torch.load('checkpoint2/final_hog.pt'))\n",
    "    stmodel.eval()\n",
    "    \n",
    "    stmodel2 = nn.Sequential(bpda, stmodel)\n",
    "    atk = torchattacks.PGD(stmodel2, eps=8/255, steps=10)\n",
    "    t = trange(len(val_loader), desc='Average Val Accuracy', leave=True) \n",
    "    for step_val, (feat,X,y) in zip(t, val_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        c=feat.to(device)\n",
    "        ##======================\n",
    "\n",
    "#         adv_images1 = atk(X/255.0, y)\n",
    "#         adv_images = adv_images1.permute(0,2,3,1).cpu().numpy().astype(np.float)*255\n",
    "\n",
    "#         for b in range(adv_images.shape[0]):\n",
    "#             adv_images[b] = val_ltp(image=adv_images[b])['image']\n",
    "#     #         for c in range(3):\n",
    "#     #             adv_images[b,:,:,c] =local_binary_pattern(adv_images[b,:,:,c], n_points, radius, 'ror')\n",
    "\n",
    "#     #     adv_images[np.isnan(adv_images)] = 0\n",
    "#     #     adv_images = (adv_images / float(2**8) -0.5) * 2\n",
    "#         adv_images = (adv_images*0.125 -0.5) * 2\n",
    "\n",
    "#         adv_images = torch.Tensor(adv_images).permute(0,3,1,2).cuda()\n",
    "        \n",
    "        norm_feat = (feat +1) / 2\n",
    "        adv_images = atk(norm_feat, y) /2-1\n",
    "        \n",
    "        \n",
    "        outputs = stmodel(adv_images)\n",
    "        outputs2 = stmodel(feat)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        val_acc2.append( (pred == y).sum().item()/y.size(0) )\n",
    "        _, pred2 = torch.max(outputs2.data, 1)\n",
    "        val_acc.append( (pred2 == y).sum().item()/y.size(0) )\n",
    "\n",
    "    #     plt.imshow(adv_images[0].permute(1,2,0).cpu().data)\n",
    "    #     plt.show()\n",
    "        t.set_description(\"Average Val Accuracy: %.5f/Robustness: %.5f\" % (np.mean(np.array(val_acc)), np.mean(np.array(val_acc2))))\n",
    "        t.refresh() # to show immediately the update\n",
    "#         im1 = adv_images[0].permute(1,2,0).cpu().numpy() \n",
    "#         plt.imshow(im1)\n",
    "#         plt.show()\n",
    "#         im2 = norm_feat[0].permute(1,2,0).cpu().numpy()\n",
    "#         plt.imshow(im2)\n",
    "#         plt.show()\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "#         break\n",
    "\n",
    "atk_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f730756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # of images is: 50000 on val mode!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bpda train:   0%|                                                                                                                                                                                                   | 0/90 [1:47:22<?, ?it/s]\n",
      "bpda loss: 0.43430: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [2:46:42<00:00, 111.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Val Accuracy: 0.59087/Robustness: 0.46181: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2084/2084 [33:04<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os, glob\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from dataset import *\n",
    "from model import *\n",
    "from torch.nn.parallel import DataParallel\n",
    "import tqdm\n",
    "import torchattacks\n",
    "from tqdm import trange\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.models as tm\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "from skimage.feature import local_binary_pattern\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torch.nn.functional as F\n",
    "##=============Config===================\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device='cuda'\n",
    "\n",
    "class BPDA(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BPDA, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 32, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 3, 3, stride=1, padding=1)\n",
    "        # an affine operation: y = Wx + b\n",
    "\n",
    "\n",
    "    def forward(self, x1):\n",
    "        x = F.leaky_relu(self.conv1(x1))\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "### original inference process ###\n",
    "\n",
    "val_ltp = A.Compose([A.Lambda(name='ltp', image=ltp_transform_train, p=1, always_apply=True)])\n",
    "\n",
    "\n",
    "val_dataset = featDataset(0, \"val.txt\", root='/hdd3/ILSVRC/Data/imagenet/', mode='val', feat='ltp')\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=24, drop_last=False, \n",
    "                                         num_workers=16, sampler=None, shuffle=True)\n",
    "    \n",
    "def atk_func():\n",
    "    t = trange(90, desc='bpda train', leave=True) \n",
    "    bpda = BPDA().to(device)\n",
    "    mse = torch.nn.MSELoss()\n",
    "    opt = torch.optim.Adam(bpda.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=30, gamma=0.1)\n",
    "    for ep in t:\n",
    "#         t = trange(len(val_loader), desc='Average Val Accuracy', leave=True) \n",
    "        loss1=0\n",
    "        for step_val, (feat,X,y) in enumerate(val_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            c=feat.to(device)\n",
    "#             import pdb\n",
    "#             pdb.set_trace()\n",
    "            opt.zero_grad()\n",
    "            pred = bpda(X)\n",
    "            loss = mse(pred, c)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "            loss1+= loss.item()\n",
    "            t.set_description(\"bpda loss: %.5f\" % (loss1/(1+step_val)))\n",
    "            t.refresh()\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    print('Start validating')\n",
    "   \n",
    "    val_acc, val_acc2 = [], []\n",
    "    \n",
    "    stmodel= tm.resnet50().to(device)\n",
    "    stmodel = DataParallel(stmodel)\n",
    "    stmodel.load_state_dict(torch.load('checkpoint2/final_hog.pt'))\n",
    "    stmodel.eval()\n",
    "    \n",
    "    stmodel2 = nn.Sequential(bpda, stmodel)\n",
    "    atk = torchattacks.PGD(stmodel2, eps=8/255, steps=10)\n",
    "    t = trange(len(val_loader), desc='Average Val Accuracy', leave=True) \n",
    "    for step_val, (feat,X,y) in zip(t, val_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        c=feat.to(device)\n",
    "        ##======================\n",
    "\n",
    "#         adv_images1 = atk(X/255.0, y)\n",
    "#         adv_images = adv_images1.permute(0,2,3,1).cpu().numpy().astype(np.float)*255\n",
    "\n",
    "#         for b in range(adv_images.shape[0]):\n",
    "#             adv_images[b] = val_ltp(image=adv_images[b])['image']\n",
    "#     #         for c in range(3):\n",
    "#     #             adv_images[b,:,:,c] =local_binary_pattern(adv_images[b,:,:,c], n_points, radius, 'ror')\n",
    "\n",
    "#     #     adv_images[np.isnan(adv_images)] = 0\n",
    "#     #     adv_images = (adv_images / float(2**8) -0.5) * 2\n",
    "#         adv_images = (adv_images*0.125 -0.5) * 2\n",
    "\n",
    "#         adv_images = torch.Tensor(adv_images).permute(0,3,1,2).cuda()\n",
    "        \n",
    "        norm_feat = (feat +1) / 2\n",
    "        adv_images = atk(norm_feat, y) /2-1\n",
    "        \n",
    "        \n",
    "        outputs = stmodel(adv_images)\n",
    "        outputs2 = stmodel(feat)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        val_acc2.append( (pred == y).sum().item()/y.size(0) )\n",
    "        _, pred2 = torch.max(outputs2.data, 1)\n",
    "        val_acc.append( (pred2 == y).sum().item()/y.size(0) )\n",
    "\n",
    "    #     plt.imshow(adv_images[0].permute(1,2,0).cpu().data)\n",
    "    #     plt.show()\n",
    "        t.set_description(\"Average Val Accuracy: %.5f/Robustness: %.5f\" % (np.mean(np.array(val_acc)), np.mean(np.array(val_acc2))))\n",
    "        t.refresh() # to show immediately the update\n",
    "#         im1 = adv_images[0].permute(1,2,0).cpu().numpy() \n",
    "#         plt.imshow(im1)\n",
    "#         plt.show()\n",
    "#         im2 = norm_feat[0].permute(1,2,0).cpu().numpy()\n",
    "#         plt.imshow(im2)\n",
    "#         plt.show()\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "#         break\n",
    "\n",
    "atk_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5c51d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # of images is: 50000 on val mode!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bpda loss: 0.60954: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [30:20:19<00:00, 1213.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Val Accuracy: 0.57298/Robustness: 0.43510: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3125/3125 [3:40:51<00:00,  4.24s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os, glob\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from dataset import *\n",
    "from model import *\n",
    "from torch.nn.parallel import DataParallel\n",
    "import tqdm\n",
    "import torchattacks\n",
    "from tqdm import trange\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.models as tm\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "from skimage.feature import local_binary_pattern\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class _ResidualDenseBlock(nn.Module):\n",
    "    \"\"\"Achieves densely connected convolutional layers.\n",
    "    `Densely Connected Convolutional Networks <https://arxiv.org/pdf/1608.06993v5.pdf>` paper.\n",
    "    Args:\n",
    "        channels (int): The number of channels in the input image.\n",
    "        growth_channels (int): The number of channels that increase in each layer of convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, growth_channels: int) -> None:\n",
    "        super(_ResidualDenseBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels + growth_channels * 0, growth_channels, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv2 = nn.Conv2d(channels + growth_channels * 1, growth_channels, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(channels + growth_channels * 2, growth_channels, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(channels + growth_channels * 3, growth_channels, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv5 = nn.Conv2d(channels + growth_channels * 4, channels, (3, 3), (1, 1), (1, 1))\n",
    "\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2, True)\n",
    "        self.identity = nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out1 = self.leaky_relu(self.conv1(x))\n",
    "        out2 = self.leaky_relu(self.conv2(torch.cat([x, out1], 1)))\n",
    "        out3 = self.leaky_relu(self.conv3(torch.cat([x, out1, out2], 1)))\n",
    "        out4 = self.leaky_relu(self.conv4(torch.cat([x, out1, out2, out3], 1)))\n",
    "        out5 = self.identity(self.conv5(torch.cat([x, out1, out2, out3, out4], 1)))\n",
    "        out = torch.mul(out5, 0.2)\n",
    "        out = torch.add(out, identity)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class _ResidualResidualDenseBlock(nn.Module):\n",
    "    \"\"\"Multi-layer residual dense convolution block.\n",
    "    Args:\n",
    "        channels (int): The number of channels in the input image.\n",
    "        growth_channels (int): The number of channels that increase in each layer of convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, growth_channels: int) -> None:\n",
    "        super(_ResidualResidualDenseBlock, self).__init__()\n",
    "        self.rdb1 = _ResidualDenseBlock(channels, growth_channels)\n",
    "        self.rdb2 = _ResidualDenseBlock(channels, growth_channels)\n",
    "        self.rdb3 = _ResidualDenseBlock(channels, growth_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.rdb1(x)\n",
    "        out = self.rdb2(out)\n",
    "        out = self.rdb3(out)\n",
    "        out = torch.mul(out, 0.2)\n",
    "        out = torch.add(out, identity)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "##=============Config===================\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device='cuda'\n",
    "\n",
    "class BPDA(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BPDA, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        self.conv2 = _ResidualResidualDenseBlock(64,16)\n",
    "        self.conv3 = _ResidualResidualDenseBlock(64,16)\n",
    "        self.conv4 = nn.Conv2d(64, 3, 3, stride=1, padding=1)\n",
    "        # an affine operation: y = Wx + b\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self, x1):\n",
    "        x = F.leaky_relu(self.conv1(x1))\n",
    "        x = (self.conv2(x))\n",
    "        x = (self.conv3(x))\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "### original inference process ###\n",
    "\n",
    "val_ltp = A.Compose([A.Lambda(name='ltp', image=ltp_transform_train, p=1, always_apply=True)])\n",
    "\n",
    "\n",
    "val_dataset = featDataset(0, \"val.txt\", root='/hdd3/ILSVRC/Data/imagenet/', mode='val', feat='ltp')\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, drop_last=False, \n",
    "                                         num_workers=16, sampler=None, shuffle=True)\n",
    "    \n",
    "def atk_func():\n",
    "    t = trange(90, desc='bpda train', leave=True) \n",
    "    bpda = BPDA().to(device)\n",
    "    mse = torch.nn.MSELoss()\n",
    "    opt = torch.optim.AdamW(bpda.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=30, gamma=0.1)\n",
    "    for ep in t:\n",
    "#         t = trange(len(val_loader), desc='Average Val Accuracy', leave=True) \n",
    "        loss1=0\n",
    "        for step_val, (feat,X,y) in enumerate(val_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            c=feat.to(device)\n",
    "#             import pdb\n",
    "#             pdb.set_trace()\n",
    "            opt.zero_grad()\n",
    "            pred = bpda(X)\n",
    "            loss = mse(pred, c)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "            loss1+= loss.item()\n",
    "            t.set_description(\"bpda loss: %.5f\" % (loss1/(1+step_val)))\n",
    "            t.refresh()\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    print('Start validating')\n",
    "   \n",
    "    val_acc, val_acc2 = [], []\n",
    "    \n",
    "    stmodel= tm.resnet50().to(device)\n",
    "    stmodel = DataParallel(stmodel)\n",
    "    stmodel.load_state_dict(torch.load('checkpoint2/final_hog.pt'))\n",
    "    stmodel.eval()\n",
    "    \n",
    "    stmodel2 = nn.Sequential(bpda, stmodel)\n",
    "    atk = torchattacks.PGD(stmodel2, eps=8/255, steps=10)\n",
    "    t = trange(len(val_loader), desc='Average Val Accuracy', leave=True) \n",
    "    for step_val, (feat,X,y) in zip(t, val_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        c=feat.to(device)\n",
    "        ##======================\n",
    "\n",
    "#         adv_images1 = atk(X/255.0, y)\n",
    "#         adv_images = adv_images1.permute(0,2,3,1).cpu().numpy().astype(np.float)*255\n",
    "\n",
    "#         for b in range(adv_images.shape[0]):\n",
    "#             adv_images[b] = val_ltp(image=adv_images[b])['image']\n",
    "#     #         for c in range(3):\n",
    "#     #             adv_images[b,:,:,c] =local_binary_pattern(adv_images[b,:,:,c], n_points, radius, 'ror')\n",
    "\n",
    "#     #     adv_images[np.isnan(adv_images)] = 0\n",
    "#     #     adv_images = (adv_images / float(2**8) -0.5) * 2\n",
    "#         adv_images = (adv_images*0.125 -0.5) * 2\n",
    "\n",
    "#         adv_images = torch.Tensor(adv_images).permute(0,3,1,2).cuda()\n",
    "        \n",
    "        norm_feat = (feat +1) / 2\n",
    "        adv_images = atk(norm_feat, y) /2-1\n",
    "        \n",
    "        \n",
    "        outputs = stmodel(adv_images)\n",
    "        outputs2 = stmodel(feat)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        val_acc2.append( (pred == y).sum().item()/y.size(0) )\n",
    "        _, pred2 = torch.max(outputs2.data, 1)\n",
    "        val_acc.append( (pred2 == y).sum().item()/y.size(0) )\n",
    "\n",
    "    #     plt.imshow(adv_images[0].permute(1,2,0).cpu().data)\n",
    "    #     plt.show()\n",
    "        t.set_description(\"Average Val Accuracy: %.5f/Robustness: %.5f\" % (np.mean(np.array(val_acc)), np.mean(np.array(val_acc2))))\n",
    "        t.refresh() # to show immediately the update\n",
    "#         im1 = adv_images[0].permute(1,2,0).cpu().numpy() \n",
    "#         plt.imshow(im1)\n",
    "#         plt.show()\n",
    "#         im2 = norm_feat[0].permute(1,2,0).cpu().numpy()\n",
    "#         plt.imshow(im2)\n",
    "#         plt.show()\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "#         break\n",
    "\n",
    "atk_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1208bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
